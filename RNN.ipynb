{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "is_working_with_easy_dataset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_text(html_text):\n",
    "    soup = BeautifulSoup(html_text)\n",
    "    return soup.get_text()\n",
    "\n",
    "def embed(model, txt):\n",
    "    txt = [txt]\n",
    "    embeddings = model.encode(txt)\n",
    "    for sentence, embedding in zip(txt, embeddings):\n",
    "        return embedding\n",
    "\n",
    "def plot_graphs(history, metric):\n",
    "    plt.plot(history.history[metric])\n",
    "    plt.plot(history.history['val_'+metric], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([metric, 'val_'+metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading in Dataset for Vectorization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if is_working_with_easy_dataset:\n",
    "    input_train_filename = \"jd_easy_train.csv\"\n",
    "    input_test_filename = \"jd_easy_test.csv\"\n",
    "else:\n",
    "    input_train_filename = \"jd_difficult_train.csv\"\n",
    "    input_test_filename = \"jd_difficult_test.csv\"\n",
    "\n",
    "jd_train = pd.read_csv(input_train_filename, keep_default_na=False)\n",
    "jd_test = pd.read_csv(input_test_filename, keep_default_na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               category         0         1         2         3         4  \\\n0     software+engineer -0.007818  0.015209 -0.032915 -0.040774 -0.075819   \n1                  arts -0.039281 -0.037813 -0.002049 -0.079996 -0.009300   \n2                    hr -0.099071  0.067754 -0.018720  0.065808 -0.019722   \n3                  arts -0.000244 -0.010329  0.005088  0.019951  0.031961   \n4                  arts  0.037742 -0.058576  0.017413 -0.007462 -0.010717   \n...                 ...       ...       ...       ...       ...       ...   \n3177  software+engineer -0.092087  0.031149 -0.008015 -0.022320 -0.046425   \n3178              sales -0.078644  0.031273  0.041027 -0.058212 -0.068799   \n3179               arts -0.101251  0.041866 -0.005444 -0.011291 -0.032258   \n3180                 hr -0.051157  0.022184  0.029747  0.018414 -0.007712   \n3181                 hr -0.037771  0.040630 -0.033029  0.056949 -0.050621   \n\n             5         6         7         8  ...       374       375  \\\n0    -0.122257  0.003905  0.105021 -0.081435  ...  0.036517  0.067738   \n1     0.014721  0.028362 -0.028484 -0.047296  ...  0.061370  0.030016   \n2    -0.006825 -0.010283  0.001540 -0.087364  ...  0.081999  0.114448   \n3    -0.004796 -0.056017  0.008362 -0.058531  ...  0.018572  0.015595   \n4    -0.022504 -0.016252  0.022974 -0.052209  ...  0.015944  0.056351   \n...        ...       ...       ...       ...  ...       ...       ...   \n3177 -0.083988  0.008692  0.036745 -0.129390  ...  0.008609  0.064561   \n3178  0.024472  0.047536  0.047297 -0.061370  ... -0.022879  0.019196   \n3179 -0.016939  0.026778  0.046210 -0.083376  ...  0.004621  0.021080   \n3180 -0.003600  0.016207  0.049001 -0.018576  ...  0.000053  0.008966   \n3181 -0.047433 -0.007329  0.009315 -0.052792  ...  0.005489  0.047084   \n\n           376       377       378       379       380       381       382  \\\n0     0.017234 -0.021146 -0.005016  0.052575  0.016892  0.011725  0.031423   \n1    -0.020944  0.025066 -0.054447  0.042434 -0.016480 -0.065129 -0.121761   \n2     0.022363 -0.051149  0.002981  0.086356  0.092362 -0.042364 -0.033669   \n3     0.026521  0.006298 -0.024210  0.076719 -0.001265 -0.029895 -0.037964   \n4     0.060758  0.049852 -0.018264  0.075948  0.001910 -0.011242 -0.045209   \n...        ...       ...       ...       ...       ...       ...       ...   \n3177 -0.016291 -0.005272 -0.021538  0.051470  0.078117 -0.018555 -0.036695   \n3178  0.019246 -0.004855  0.016442  0.089635  0.074209 -0.086454 -0.098238   \n3179  0.026186  0.022296 -0.041951  0.082195  0.048774 -0.097376 -0.085289   \n3180 -0.015656 -0.005649 -0.080121  0.053882  0.070258 -0.079552 -0.019765   \n3181  0.037522 -0.024134 -0.032097  0.051435  0.104937 -0.089167 -0.052026   \n\n           383  \n0     0.008097  \n1     0.036031  \n2     0.060429  \n3     0.052187  \n4     0.029765  \n...        ...  \n3177 -0.013603  \n3178  0.072741  \n3179  0.013674  \n3180  0.002172  \n3181  0.026151  \n\n[3182 rows x 385 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>software+engineer</td>\n      <td>-0.007818</td>\n      <td>0.015209</td>\n      <td>-0.032915</td>\n      <td>-0.040774</td>\n      <td>-0.075819</td>\n      <td>-0.122257</td>\n      <td>0.003905</td>\n      <td>0.105021</td>\n      <td>-0.081435</td>\n      <td>...</td>\n      <td>0.036517</td>\n      <td>0.067738</td>\n      <td>0.017234</td>\n      <td>-0.021146</td>\n      <td>-0.005016</td>\n      <td>0.052575</td>\n      <td>0.016892</td>\n      <td>0.011725</td>\n      <td>0.031423</td>\n      <td>0.008097</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>arts</td>\n      <td>-0.039281</td>\n      <td>-0.037813</td>\n      <td>-0.002049</td>\n      <td>-0.079996</td>\n      <td>-0.009300</td>\n      <td>0.014721</td>\n      <td>0.028362</td>\n      <td>-0.028484</td>\n      <td>-0.047296</td>\n      <td>...</td>\n      <td>0.061370</td>\n      <td>0.030016</td>\n      <td>-0.020944</td>\n      <td>0.025066</td>\n      <td>-0.054447</td>\n      <td>0.042434</td>\n      <td>-0.016480</td>\n      <td>-0.065129</td>\n      <td>-0.121761</td>\n      <td>0.036031</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hr</td>\n      <td>-0.099071</td>\n      <td>0.067754</td>\n      <td>-0.018720</td>\n      <td>0.065808</td>\n      <td>-0.019722</td>\n      <td>-0.006825</td>\n      <td>-0.010283</td>\n      <td>0.001540</td>\n      <td>-0.087364</td>\n      <td>...</td>\n      <td>0.081999</td>\n      <td>0.114448</td>\n      <td>0.022363</td>\n      <td>-0.051149</td>\n      <td>0.002981</td>\n      <td>0.086356</td>\n      <td>0.092362</td>\n      <td>-0.042364</td>\n      <td>-0.033669</td>\n      <td>0.060429</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>arts</td>\n      <td>-0.000244</td>\n      <td>-0.010329</td>\n      <td>0.005088</td>\n      <td>0.019951</td>\n      <td>0.031961</td>\n      <td>-0.004796</td>\n      <td>-0.056017</td>\n      <td>0.008362</td>\n      <td>-0.058531</td>\n      <td>...</td>\n      <td>0.018572</td>\n      <td>0.015595</td>\n      <td>0.026521</td>\n      <td>0.006298</td>\n      <td>-0.024210</td>\n      <td>0.076719</td>\n      <td>-0.001265</td>\n      <td>-0.029895</td>\n      <td>-0.037964</td>\n      <td>0.052187</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arts</td>\n      <td>0.037742</td>\n      <td>-0.058576</td>\n      <td>0.017413</td>\n      <td>-0.007462</td>\n      <td>-0.010717</td>\n      <td>-0.022504</td>\n      <td>-0.016252</td>\n      <td>0.022974</td>\n      <td>-0.052209</td>\n      <td>...</td>\n      <td>0.015944</td>\n      <td>0.056351</td>\n      <td>0.060758</td>\n      <td>0.049852</td>\n      <td>-0.018264</td>\n      <td>0.075948</td>\n      <td>0.001910</td>\n      <td>-0.011242</td>\n      <td>-0.045209</td>\n      <td>0.029765</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3177</th>\n      <td>software+engineer</td>\n      <td>-0.092087</td>\n      <td>0.031149</td>\n      <td>-0.008015</td>\n      <td>-0.022320</td>\n      <td>-0.046425</td>\n      <td>-0.083988</td>\n      <td>0.008692</td>\n      <td>0.036745</td>\n      <td>-0.129390</td>\n      <td>...</td>\n      <td>0.008609</td>\n      <td>0.064561</td>\n      <td>-0.016291</td>\n      <td>-0.005272</td>\n      <td>-0.021538</td>\n      <td>0.051470</td>\n      <td>0.078117</td>\n      <td>-0.018555</td>\n      <td>-0.036695</td>\n      <td>-0.013603</td>\n    </tr>\n    <tr>\n      <th>3178</th>\n      <td>sales</td>\n      <td>-0.078644</td>\n      <td>0.031273</td>\n      <td>0.041027</td>\n      <td>-0.058212</td>\n      <td>-0.068799</td>\n      <td>0.024472</td>\n      <td>0.047536</td>\n      <td>0.047297</td>\n      <td>-0.061370</td>\n      <td>...</td>\n      <td>-0.022879</td>\n      <td>0.019196</td>\n      <td>0.019246</td>\n      <td>-0.004855</td>\n      <td>0.016442</td>\n      <td>0.089635</td>\n      <td>0.074209</td>\n      <td>-0.086454</td>\n      <td>-0.098238</td>\n      <td>0.072741</td>\n    </tr>\n    <tr>\n      <th>3179</th>\n      <td>arts</td>\n      <td>-0.101251</td>\n      <td>0.041866</td>\n      <td>-0.005444</td>\n      <td>-0.011291</td>\n      <td>-0.032258</td>\n      <td>-0.016939</td>\n      <td>0.026778</td>\n      <td>0.046210</td>\n      <td>-0.083376</td>\n      <td>...</td>\n      <td>0.004621</td>\n      <td>0.021080</td>\n      <td>0.026186</td>\n      <td>0.022296</td>\n      <td>-0.041951</td>\n      <td>0.082195</td>\n      <td>0.048774</td>\n      <td>-0.097376</td>\n      <td>-0.085289</td>\n      <td>0.013674</td>\n    </tr>\n    <tr>\n      <th>3180</th>\n      <td>hr</td>\n      <td>-0.051157</td>\n      <td>0.022184</td>\n      <td>0.029747</td>\n      <td>0.018414</td>\n      <td>-0.007712</td>\n      <td>-0.003600</td>\n      <td>0.016207</td>\n      <td>0.049001</td>\n      <td>-0.018576</td>\n      <td>...</td>\n      <td>0.000053</td>\n      <td>0.008966</td>\n      <td>-0.015656</td>\n      <td>-0.005649</td>\n      <td>-0.080121</td>\n      <td>0.053882</td>\n      <td>0.070258</td>\n      <td>-0.079552</td>\n      <td>-0.019765</td>\n      <td>0.002172</td>\n    </tr>\n    <tr>\n      <th>3181</th>\n      <td>hr</td>\n      <td>-0.037771</td>\n      <td>0.040630</td>\n      <td>-0.033029</td>\n      <td>0.056949</td>\n      <td>-0.050621</td>\n      <td>-0.047433</td>\n      <td>-0.007329</td>\n      <td>0.009315</td>\n      <td>-0.052792</td>\n      <td>...</td>\n      <td>0.005489</td>\n      <td>0.047084</td>\n      <td>0.037522</td>\n      <td>-0.024134</td>\n      <td>-0.032097</td>\n      <td>0.051435</td>\n      <td>0.104937</td>\n      <td>-0.089167</td>\n      <td>-0.052026</td>\n      <td>0.026151</td>\n    </tr>\n  </tbody>\n</table>\n<p>3182 rows × 385 columns</p>\n</div>"
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors_train = list(\n",
    "    pd.Series.tolist(jd_train.description.apply(lambda x: embed(model, get_text(x)))))\n",
    "embedding_train = pd.concat(\n",
    "    [jd_train.category, pd.DataFrame(embedding_vectors_train)], axis=1)\n",
    "embedding_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "              category         0         1         2         3         4  \\\n0    software+engineer -0.113818  0.008952 -0.004451  0.003387  0.041243   \n1                sales -0.019982 -0.019572 -0.043766  0.038807 -0.021798   \n2                sales -0.061115  0.037327 -0.035323  0.007244 -0.014231   \n3                sales -0.110860  0.012782 -0.030584 -0.077872 -0.102458   \n4                 arts -0.044880  0.017243  0.052809 -0.012010  0.038006   \n..                 ...       ...       ...       ...       ...       ...   \n791  software+engineer -0.131392 -0.029033 -0.082744 -0.039305 -0.028481   \n792  software+engineer -0.043274 -0.032123  0.041134 -0.017565  0.032743   \n793  software+engineer -0.006800 -0.087576 -0.029101 -0.043830 -0.068833   \n794                 hr -0.128770  0.043694 -0.002058  0.047944 -0.053523   \n795                 hr -0.079189  0.014116 -0.021597  0.034801 -0.050730   \n\n            5         6         7         8  ...       374       375  \\\n0   -0.074476  0.027237  0.074545 -0.080968  ...  0.016368  0.115178   \n1   -0.003498 -0.008579 -0.007094  0.017747  ...  0.023369 -0.032173   \n2    0.054096  0.095702  0.017702 -0.064049  ...  0.024937  0.007117   \n3    0.048481  0.027282  0.055432 -0.007119  ... -0.057282  0.060048   \n4   -0.025841  0.002447  0.005194 -0.023129  ...  0.014638  0.062186   \n..        ...       ...       ...       ...  ...       ...       ...   \n791 -0.063193 -0.057688  0.128488 -0.072210  ... -0.023796  0.086397   \n792 -0.072493  0.013035 -0.040865  0.005068  ...  0.003571  0.061880   \n793 -0.016611  0.032965  0.086794 -0.112048  ...  0.093700  0.060009   \n794  0.042907  0.058572 -0.007716 -0.058442  ... -0.018871  0.036778   \n795 -0.014727 -0.056692 -0.020434 -0.031112  ...  0.056226  0.025051   \n\n          376       377       378       379       380       381       382  \\\n0    0.065218 -0.074784  0.057262  0.082102  0.059299 -0.031293  0.007032   \n1   -0.008954 -0.028408 -0.041258 -0.016728  0.078255 -0.043575  0.043920   \n2    0.029717  0.036748 -0.017619  0.084793  0.017758 -0.004776 -0.067190   \n3    0.012040  0.056503 -0.008248  0.102686 -0.004278 -0.015446 -0.055078   \n4    0.076078 -0.041519 -0.023763  0.048595  0.060352 -0.011345 -0.059987   \n..        ...       ...       ...       ...       ...       ...       ...   \n791 -0.071659 -0.031082 -0.003570  0.047519  0.033251 -0.166673 -0.007538   \n792  0.018539 -0.087545  0.026615  0.099625  0.018813 -0.029922  0.014897   \n793 -0.031102  0.073509  0.054705  0.061826  0.028178 -0.001595 -0.046012   \n794 -0.042918 -0.002689 -0.052095  0.123027  0.064848 -0.024640  0.003905   \n795  0.044193 -0.059260 -0.099940  0.062814  0.032975 -0.039858  0.017513   \n\n          383  \n0    0.071702  \n1   -0.008786  \n2    0.031323  \n3    0.049244  \n4    0.039882  \n..        ...  \n791 -0.031994  \n792 -0.003446  \n793 -0.033700  \n794  0.014744  \n795 -0.004559  \n\n[796 rows x 385 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>software+engineer</td>\n      <td>-0.113818</td>\n      <td>0.008952</td>\n      <td>-0.004451</td>\n      <td>0.003387</td>\n      <td>0.041243</td>\n      <td>-0.074476</td>\n      <td>0.027237</td>\n      <td>0.074545</td>\n      <td>-0.080968</td>\n      <td>...</td>\n      <td>0.016368</td>\n      <td>0.115178</td>\n      <td>0.065218</td>\n      <td>-0.074784</td>\n      <td>0.057262</td>\n      <td>0.082102</td>\n      <td>0.059299</td>\n      <td>-0.031293</td>\n      <td>0.007032</td>\n      <td>0.071702</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sales</td>\n      <td>-0.019982</td>\n      <td>-0.019572</td>\n      <td>-0.043766</td>\n      <td>0.038807</td>\n      <td>-0.021798</td>\n      <td>-0.003498</td>\n      <td>-0.008579</td>\n      <td>-0.007094</td>\n      <td>0.017747</td>\n      <td>...</td>\n      <td>0.023369</td>\n      <td>-0.032173</td>\n      <td>-0.008954</td>\n      <td>-0.028408</td>\n      <td>-0.041258</td>\n      <td>-0.016728</td>\n      <td>0.078255</td>\n      <td>-0.043575</td>\n      <td>0.043920</td>\n      <td>-0.008786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sales</td>\n      <td>-0.061115</td>\n      <td>0.037327</td>\n      <td>-0.035323</td>\n      <td>0.007244</td>\n      <td>-0.014231</td>\n      <td>0.054096</td>\n      <td>0.095702</td>\n      <td>0.017702</td>\n      <td>-0.064049</td>\n      <td>...</td>\n      <td>0.024937</td>\n      <td>0.007117</td>\n      <td>0.029717</td>\n      <td>0.036748</td>\n      <td>-0.017619</td>\n      <td>0.084793</td>\n      <td>0.017758</td>\n      <td>-0.004776</td>\n      <td>-0.067190</td>\n      <td>0.031323</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sales</td>\n      <td>-0.110860</td>\n      <td>0.012782</td>\n      <td>-0.030584</td>\n      <td>-0.077872</td>\n      <td>-0.102458</td>\n      <td>0.048481</td>\n      <td>0.027282</td>\n      <td>0.055432</td>\n      <td>-0.007119</td>\n      <td>...</td>\n      <td>-0.057282</td>\n      <td>0.060048</td>\n      <td>0.012040</td>\n      <td>0.056503</td>\n      <td>-0.008248</td>\n      <td>0.102686</td>\n      <td>-0.004278</td>\n      <td>-0.015446</td>\n      <td>-0.055078</td>\n      <td>0.049244</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arts</td>\n      <td>-0.044880</td>\n      <td>0.017243</td>\n      <td>0.052809</td>\n      <td>-0.012010</td>\n      <td>0.038006</td>\n      <td>-0.025841</td>\n      <td>0.002447</td>\n      <td>0.005194</td>\n      <td>-0.023129</td>\n      <td>...</td>\n      <td>0.014638</td>\n      <td>0.062186</td>\n      <td>0.076078</td>\n      <td>-0.041519</td>\n      <td>-0.023763</td>\n      <td>0.048595</td>\n      <td>0.060352</td>\n      <td>-0.011345</td>\n      <td>-0.059987</td>\n      <td>0.039882</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>791</th>\n      <td>software+engineer</td>\n      <td>-0.131392</td>\n      <td>-0.029033</td>\n      <td>-0.082744</td>\n      <td>-0.039305</td>\n      <td>-0.028481</td>\n      <td>-0.063193</td>\n      <td>-0.057688</td>\n      <td>0.128488</td>\n      <td>-0.072210</td>\n      <td>...</td>\n      <td>-0.023796</td>\n      <td>0.086397</td>\n      <td>-0.071659</td>\n      <td>-0.031082</td>\n      <td>-0.003570</td>\n      <td>0.047519</td>\n      <td>0.033251</td>\n      <td>-0.166673</td>\n      <td>-0.007538</td>\n      <td>-0.031994</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>software+engineer</td>\n      <td>-0.043274</td>\n      <td>-0.032123</td>\n      <td>0.041134</td>\n      <td>-0.017565</td>\n      <td>0.032743</td>\n      <td>-0.072493</td>\n      <td>0.013035</td>\n      <td>-0.040865</td>\n      <td>0.005068</td>\n      <td>...</td>\n      <td>0.003571</td>\n      <td>0.061880</td>\n      <td>0.018539</td>\n      <td>-0.087545</td>\n      <td>0.026615</td>\n      <td>0.099625</td>\n      <td>0.018813</td>\n      <td>-0.029922</td>\n      <td>0.014897</td>\n      <td>-0.003446</td>\n    </tr>\n    <tr>\n      <th>793</th>\n      <td>software+engineer</td>\n      <td>-0.006800</td>\n      <td>-0.087576</td>\n      <td>-0.029101</td>\n      <td>-0.043830</td>\n      <td>-0.068833</td>\n      <td>-0.016611</td>\n      <td>0.032965</td>\n      <td>0.086794</td>\n      <td>-0.112048</td>\n      <td>...</td>\n      <td>0.093700</td>\n      <td>0.060009</td>\n      <td>-0.031102</td>\n      <td>0.073509</td>\n      <td>0.054705</td>\n      <td>0.061826</td>\n      <td>0.028178</td>\n      <td>-0.001595</td>\n      <td>-0.046012</td>\n      <td>-0.033700</td>\n    </tr>\n    <tr>\n      <th>794</th>\n      <td>hr</td>\n      <td>-0.128770</td>\n      <td>0.043694</td>\n      <td>-0.002058</td>\n      <td>0.047944</td>\n      <td>-0.053523</td>\n      <td>0.042907</td>\n      <td>0.058572</td>\n      <td>-0.007716</td>\n      <td>-0.058442</td>\n      <td>...</td>\n      <td>-0.018871</td>\n      <td>0.036778</td>\n      <td>-0.042918</td>\n      <td>-0.002689</td>\n      <td>-0.052095</td>\n      <td>0.123027</td>\n      <td>0.064848</td>\n      <td>-0.024640</td>\n      <td>0.003905</td>\n      <td>0.014744</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>hr</td>\n      <td>-0.079189</td>\n      <td>0.014116</td>\n      <td>-0.021597</td>\n      <td>0.034801</td>\n      <td>-0.050730</td>\n      <td>-0.014727</td>\n      <td>-0.056692</td>\n      <td>-0.020434</td>\n      <td>-0.031112</td>\n      <td>...</td>\n      <td>0.056226</td>\n      <td>0.025051</td>\n      <td>0.044193</td>\n      <td>-0.059260</td>\n      <td>-0.099940</td>\n      <td>0.062814</td>\n      <td>0.032975</td>\n      <td>-0.039858</td>\n      <td>0.017513</td>\n      <td>-0.004559</td>\n    </tr>\n  </tbody>\n</table>\n<p>796 rows × 385 columns</p>\n</div>"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_vectors_test = list(\n",
    "    pd.Series.tolist(jd_test.description.apply(lambda x: embed(model, get_text(x)))))\n",
    "embedding_test = pd.concat(\n",
    "    [jd_test.category, pd.DataFrame(embedding_vectors_test)], axis=1)\n",
    "embedding_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if is_working_with_easy_dataset:\n",
    "    output_train_filename = \"embedding_easy_train.csv\"\n",
    "    output_test_filename = \"embedding_easy_test.csv\"\n",
    "else:\n",
    "    output_train_filename = \"embedding_difficult_train.csv\"\n",
    "    output_test_filename = \"embedding_difficult_test.csv\"\n",
    "\n",
    "embedding_train.to_csv(output_train_filename, index=False)\n",
    "embedding_test.to_csv(output_test_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Start of RNN building\n",
    "\n",
    "We will first create an RNN model on the easy dataset, analyse the results, and then create the RNN model on the hard dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Easy Dataset (Distinct Job Categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "is_working_with_easy_dataset = True"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "if is_working_with_easy_dataset:\n",
    "    input_train_filename = \"embedding_easy_train.csv\"\n",
    "    input_test_filename = \"embedding_easy_test.csv\"\n",
    "else:\n",
    "    input_train_filename = \"embedding_difficult_train.csv\"\n",
    "    input_test_filename = \"embedding_difficult_test.csv\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "jd_train = pd.read_csv(input_train_filename, keep_default_na=False)\n",
    "jd_test = pd.read_csv(input_test_filename, keep_default_na=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "               category         0         1         2         3         4  \\\n0     software+engineer -0.007818  0.015209 -0.032915 -0.040774 -0.075819   \n1                  arts -0.039281 -0.037813 -0.002049 -0.079996 -0.009300   \n2                    hr -0.099071  0.067754 -0.018720  0.065808 -0.019722   \n3                  arts -0.000244 -0.010329  0.005088  0.019951  0.031961   \n4                  arts  0.037742 -0.058576  0.017413 -0.007462 -0.010717   \n...                 ...       ...       ...       ...       ...       ...   \n3177  software+engineer -0.092087  0.031149 -0.008015 -0.022320 -0.046425   \n3178              sales -0.078644  0.031273  0.041027 -0.058212 -0.068799   \n3179               arts -0.101251  0.041866 -0.005444 -0.011291 -0.032258   \n3180                 hr -0.051157  0.022184  0.029747  0.018414 -0.007712   \n3181                 hr -0.037771  0.040630 -0.033029  0.056949 -0.050621   \n\n             5         6         7         8  ...       374       375  \\\n0    -0.122257  0.003905  0.105021 -0.081435  ...  0.036517  0.067738   \n1     0.014721  0.028362 -0.028484 -0.047296  ...  0.061370  0.030016   \n2    -0.006825 -0.010283  0.001540 -0.087364  ...  0.081999  0.114448   \n3    -0.004796 -0.056017  0.008362 -0.058531  ...  0.018572  0.015595   \n4    -0.022504 -0.016252  0.022974 -0.052209  ...  0.015944  0.056351   \n...        ...       ...       ...       ...  ...       ...       ...   \n3177 -0.083988  0.008692  0.036745 -0.129390  ...  0.008609  0.064561   \n3178  0.024472  0.047536  0.047297 -0.061370  ... -0.022879  0.019196   \n3179 -0.016939  0.026778  0.046210 -0.083376  ...  0.004621  0.021080   \n3180 -0.003600  0.016207  0.049001 -0.018576  ...  0.000053  0.008966   \n3181 -0.047433 -0.007329  0.009315 -0.052792  ...  0.005489  0.047084   \n\n           376       377       378       379       380       381       382  \\\n0     0.017234 -0.021146 -0.005016  0.052575  0.016892  0.011725  0.031423   \n1    -0.020944  0.025066 -0.054447  0.042434 -0.016480 -0.065129 -0.121761   \n2     0.022363 -0.051149  0.002981  0.086356  0.092362 -0.042364 -0.033669   \n3     0.026521  0.006298 -0.024210  0.076719 -0.001265 -0.029895 -0.037964   \n4     0.060758  0.049852 -0.018264  0.075948  0.001910 -0.011242 -0.045209   \n...        ...       ...       ...       ...       ...       ...       ...   \n3177 -0.016291 -0.005272 -0.021538  0.051470  0.078117 -0.018555 -0.036695   \n3178  0.019246 -0.004855  0.016442  0.089635  0.074209 -0.086454 -0.098238   \n3179  0.026186  0.022296 -0.041951  0.082195  0.048774 -0.097376 -0.085289   \n3180 -0.015656 -0.005649 -0.080121  0.053882  0.070258 -0.079552 -0.019765   \n3181  0.037522 -0.024134 -0.032097  0.051435  0.104937 -0.089167 -0.052026   \n\n           383  \n0     0.008097  \n1     0.036031  \n2     0.060429  \n3     0.052187  \n4     0.029765  \n...        ...  \n3177 -0.013603  \n3178  0.072741  \n3179  0.013674  \n3180  0.002172  \n3181  0.026151  \n\n[3182 rows x 385 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>software+engineer</td>\n      <td>-0.007818</td>\n      <td>0.015209</td>\n      <td>-0.032915</td>\n      <td>-0.040774</td>\n      <td>-0.075819</td>\n      <td>-0.122257</td>\n      <td>0.003905</td>\n      <td>0.105021</td>\n      <td>-0.081435</td>\n      <td>...</td>\n      <td>0.036517</td>\n      <td>0.067738</td>\n      <td>0.017234</td>\n      <td>-0.021146</td>\n      <td>-0.005016</td>\n      <td>0.052575</td>\n      <td>0.016892</td>\n      <td>0.011725</td>\n      <td>0.031423</td>\n      <td>0.008097</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>arts</td>\n      <td>-0.039281</td>\n      <td>-0.037813</td>\n      <td>-0.002049</td>\n      <td>-0.079996</td>\n      <td>-0.009300</td>\n      <td>0.014721</td>\n      <td>0.028362</td>\n      <td>-0.028484</td>\n      <td>-0.047296</td>\n      <td>...</td>\n      <td>0.061370</td>\n      <td>0.030016</td>\n      <td>-0.020944</td>\n      <td>0.025066</td>\n      <td>-0.054447</td>\n      <td>0.042434</td>\n      <td>-0.016480</td>\n      <td>-0.065129</td>\n      <td>-0.121761</td>\n      <td>0.036031</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>hr</td>\n      <td>-0.099071</td>\n      <td>0.067754</td>\n      <td>-0.018720</td>\n      <td>0.065808</td>\n      <td>-0.019722</td>\n      <td>-0.006825</td>\n      <td>-0.010283</td>\n      <td>0.001540</td>\n      <td>-0.087364</td>\n      <td>...</td>\n      <td>0.081999</td>\n      <td>0.114448</td>\n      <td>0.022363</td>\n      <td>-0.051149</td>\n      <td>0.002981</td>\n      <td>0.086356</td>\n      <td>0.092362</td>\n      <td>-0.042364</td>\n      <td>-0.033669</td>\n      <td>0.060429</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>arts</td>\n      <td>-0.000244</td>\n      <td>-0.010329</td>\n      <td>0.005088</td>\n      <td>0.019951</td>\n      <td>0.031961</td>\n      <td>-0.004796</td>\n      <td>-0.056017</td>\n      <td>0.008362</td>\n      <td>-0.058531</td>\n      <td>...</td>\n      <td>0.018572</td>\n      <td>0.015595</td>\n      <td>0.026521</td>\n      <td>0.006298</td>\n      <td>-0.024210</td>\n      <td>0.076719</td>\n      <td>-0.001265</td>\n      <td>-0.029895</td>\n      <td>-0.037964</td>\n      <td>0.052187</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arts</td>\n      <td>0.037742</td>\n      <td>-0.058576</td>\n      <td>0.017413</td>\n      <td>-0.007462</td>\n      <td>-0.010717</td>\n      <td>-0.022504</td>\n      <td>-0.016252</td>\n      <td>0.022974</td>\n      <td>-0.052209</td>\n      <td>...</td>\n      <td>0.015944</td>\n      <td>0.056351</td>\n      <td>0.060758</td>\n      <td>0.049852</td>\n      <td>-0.018264</td>\n      <td>0.075948</td>\n      <td>0.001910</td>\n      <td>-0.011242</td>\n      <td>-0.045209</td>\n      <td>0.029765</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3177</th>\n      <td>software+engineer</td>\n      <td>-0.092087</td>\n      <td>0.031149</td>\n      <td>-0.008015</td>\n      <td>-0.022320</td>\n      <td>-0.046425</td>\n      <td>-0.083988</td>\n      <td>0.008692</td>\n      <td>0.036745</td>\n      <td>-0.129390</td>\n      <td>...</td>\n      <td>0.008609</td>\n      <td>0.064561</td>\n      <td>-0.016291</td>\n      <td>-0.005272</td>\n      <td>-0.021538</td>\n      <td>0.051470</td>\n      <td>0.078117</td>\n      <td>-0.018555</td>\n      <td>-0.036695</td>\n      <td>-0.013603</td>\n    </tr>\n    <tr>\n      <th>3178</th>\n      <td>sales</td>\n      <td>-0.078644</td>\n      <td>0.031273</td>\n      <td>0.041027</td>\n      <td>-0.058212</td>\n      <td>-0.068799</td>\n      <td>0.024472</td>\n      <td>0.047536</td>\n      <td>0.047297</td>\n      <td>-0.061370</td>\n      <td>...</td>\n      <td>-0.022879</td>\n      <td>0.019196</td>\n      <td>0.019246</td>\n      <td>-0.004855</td>\n      <td>0.016442</td>\n      <td>0.089635</td>\n      <td>0.074209</td>\n      <td>-0.086454</td>\n      <td>-0.098238</td>\n      <td>0.072741</td>\n    </tr>\n    <tr>\n      <th>3179</th>\n      <td>arts</td>\n      <td>-0.101251</td>\n      <td>0.041866</td>\n      <td>-0.005444</td>\n      <td>-0.011291</td>\n      <td>-0.032258</td>\n      <td>-0.016939</td>\n      <td>0.026778</td>\n      <td>0.046210</td>\n      <td>-0.083376</td>\n      <td>...</td>\n      <td>0.004621</td>\n      <td>0.021080</td>\n      <td>0.026186</td>\n      <td>0.022296</td>\n      <td>-0.041951</td>\n      <td>0.082195</td>\n      <td>0.048774</td>\n      <td>-0.097376</td>\n      <td>-0.085289</td>\n      <td>0.013674</td>\n    </tr>\n    <tr>\n      <th>3180</th>\n      <td>hr</td>\n      <td>-0.051157</td>\n      <td>0.022184</td>\n      <td>0.029747</td>\n      <td>0.018414</td>\n      <td>-0.007712</td>\n      <td>-0.003600</td>\n      <td>0.016207</td>\n      <td>0.049001</td>\n      <td>-0.018576</td>\n      <td>...</td>\n      <td>0.000053</td>\n      <td>0.008966</td>\n      <td>-0.015656</td>\n      <td>-0.005649</td>\n      <td>-0.080121</td>\n      <td>0.053882</td>\n      <td>0.070258</td>\n      <td>-0.079552</td>\n      <td>-0.019765</td>\n      <td>0.002172</td>\n    </tr>\n    <tr>\n      <th>3181</th>\n      <td>hr</td>\n      <td>-0.037771</td>\n      <td>0.040630</td>\n      <td>-0.033029</td>\n      <td>0.056949</td>\n      <td>-0.050621</td>\n      <td>-0.047433</td>\n      <td>-0.007329</td>\n      <td>0.009315</td>\n      <td>-0.052792</td>\n      <td>...</td>\n      <td>0.005489</td>\n      <td>0.047084</td>\n      <td>0.037522</td>\n      <td>-0.024134</td>\n      <td>-0.032097</td>\n      <td>0.051435</td>\n      <td>0.104937</td>\n      <td>-0.089167</td>\n      <td>-0.052026</td>\n      <td>0.026151</td>\n    </tr>\n  </tbody>\n</table>\n<p>3182 rows × 385 columns</p>\n</div>"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "              category         0         1         2         3         4  \\\n0    software+engineer -0.113818  0.008952 -0.004451  0.003387  0.041243   \n1                sales -0.019982 -0.019572 -0.043766  0.038807 -0.021798   \n2                sales -0.061115  0.037327 -0.035323  0.007244 -0.014231   \n3                sales -0.110860  0.012782 -0.030584 -0.077872 -0.102458   \n4                 arts -0.044880  0.017243  0.052809 -0.012010  0.038006   \n..                 ...       ...       ...       ...       ...       ...   \n791  software+engineer -0.131392 -0.029033 -0.082744 -0.039305 -0.028481   \n792  software+engineer -0.043274 -0.032123  0.041134 -0.017565  0.032743   \n793  software+engineer -0.006800 -0.087576 -0.029101 -0.043830 -0.068833   \n794                 hr -0.128770  0.043694 -0.002058  0.047944 -0.053523   \n795                 hr -0.079189  0.014116 -0.021597  0.034801 -0.050730   \n\n            5         6         7         8  ...       374       375  \\\n0   -0.074476  0.027237  0.074545 -0.080968  ...  0.016368  0.115178   \n1   -0.003498 -0.008579 -0.007094  0.017747  ...  0.023369 -0.032173   \n2    0.054096  0.095702  0.017702 -0.064049  ...  0.024937  0.007117   \n3    0.048481  0.027282  0.055432 -0.007119  ... -0.057282  0.060048   \n4   -0.025841  0.002447  0.005194 -0.023129  ...  0.014638  0.062186   \n..        ...       ...       ...       ...  ...       ...       ...   \n791 -0.063193 -0.057688  0.128488 -0.072210  ... -0.023796  0.086397   \n792 -0.072493  0.013035 -0.040865  0.005068  ...  0.003571  0.061880   \n793 -0.016611  0.032965  0.086794 -0.112048  ...  0.093700  0.060009   \n794  0.042907  0.058572 -0.007716 -0.058442  ... -0.018871  0.036778   \n795 -0.014727 -0.056692 -0.020434 -0.031112  ...  0.056226  0.025051   \n\n          376       377       378       379       380       381       382  \\\n0    0.065218 -0.074784  0.057262  0.082102  0.059299 -0.031293  0.007032   \n1   -0.008954 -0.028408 -0.041258 -0.016728  0.078255 -0.043575  0.043920   \n2    0.029717  0.036748 -0.017619  0.084793  0.017758 -0.004776 -0.067190   \n3    0.012040  0.056503 -0.008248  0.102686 -0.004278 -0.015446 -0.055078   \n4    0.076078 -0.041519 -0.023763  0.048595  0.060352 -0.011345 -0.059987   \n..        ...       ...       ...       ...       ...       ...       ...   \n791 -0.071659 -0.031082 -0.003570  0.047519  0.033251 -0.166673 -0.007538   \n792  0.018539 -0.087545  0.026615  0.099625  0.018813 -0.029922  0.014897   \n793 -0.031102  0.073509  0.054705  0.061826  0.028178 -0.001595 -0.046012   \n794 -0.042918 -0.002689 -0.052095  0.123027  0.064848 -0.024640  0.003905   \n795  0.044193 -0.059260 -0.099940  0.062814  0.032975 -0.039858  0.017513   \n\n          383  \n0    0.071702  \n1   -0.008786  \n2    0.031323  \n3    0.049244  \n4    0.039882  \n..        ...  \n791 -0.031994  \n792 -0.003446  \n793 -0.033700  \n794  0.014744  \n795 -0.004559  \n\n[796 rows x 385 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>category</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>374</th>\n      <th>375</th>\n      <th>376</th>\n      <th>377</th>\n      <th>378</th>\n      <th>379</th>\n      <th>380</th>\n      <th>381</th>\n      <th>382</th>\n      <th>383</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>software+engineer</td>\n      <td>-0.113818</td>\n      <td>0.008952</td>\n      <td>-0.004451</td>\n      <td>0.003387</td>\n      <td>0.041243</td>\n      <td>-0.074476</td>\n      <td>0.027237</td>\n      <td>0.074545</td>\n      <td>-0.080968</td>\n      <td>...</td>\n      <td>0.016368</td>\n      <td>0.115178</td>\n      <td>0.065218</td>\n      <td>-0.074784</td>\n      <td>0.057262</td>\n      <td>0.082102</td>\n      <td>0.059299</td>\n      <td>-0.031293</td>\n      <td>0.007032</td>\n      <td>0.071702</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>sales</td>\n      <td>-0.019982</td>\n      <td>-0.019572</td>\n      <td>-0.043766</td>\n      <td>0.038807</td>\n      <td>-0.021798</td>\n      <td>-0.003498</td>\n      <td>-0.008579</td>\n      <td>-0.007094</td>\n      <td>0.017747</td>\n      <td>...</td>\n      <td>0.023369</td>\n      <td>-0.032173</td>\n      <td>-0.008954</td>\n      <td>-0.028408</td>\n      <td>-0.041258</td>\n      <td>-0.016728</td>\n      <td>0.078255</td>\n      <td>-0.043575</td>\n      <td>0.043920</td>\n      <td>-0.008786</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sales</td>\n      <td>-0.061115</td>\n      <td>0.037327</td>\n      <td>-0.035323</td>\n      <td>0.007244</td>\n      <td>-0.014231</td>\n      <td>0.054096</td>\n      <td>0.095702</td>\n      <td>0.017702</td>\n      <td>-0.064049</td>\n      <td>...</td>\n      <td>0.024937</td>\n      <td>0.007117</td>\n      <td>0.029717</td>\n      <td>0.036748</td>\n      <td>-0.017619</td>\n      <td>0.084793</td>\n      <td>0.017758</td>\n      <td>-0.004776</td>\n      <td>-0.067190</td>\n      <td>0.031323</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>sales</td>\n      <td>-0.110860</td>\n      <td>0.012782</td>\n      <td>-0.030584</td>\n      <td>-0.077872</td>\n      <td>-0.102458</td>\n      <td>0.048481</td>\n      <td>0.027282</td>\n      <td>0.055432</td>\n      <td>-0.007119</td>\n      <td>...</td>\n      <td>-0.057282</td>\n      <td>0.060048</td>\n      <td>0.012040</td>\n      <td>0.056503</td>\n      <td>-0.008248</td>\n      <td>0.102686</td>\n      <td>-0.004278</td>\n      <td>-0.015446</td>\n      <td>-0.055078</td>\n      <td>0.049244</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>arts</td>\n      <td>-0.044880</td>\n      <td>0.017243</td>\n      <td>0.052809</td>\n      <td>-0.012010</td>\n      <td>0.038006</td>\n      <td>-0.025841</td>\n      <td>0.002447</td>\n      <td>0.005194</td>\n      <td>-0.023129</td>\n      <td>...</td>\n      <td>0.014638</td>\n      <td>0.062186</td>\n      <td>0.076078</td>\n      <td>-0.041519</td>\n      <td>-0.023763</td>\n      <td>0.048595</td>\n      <td>0.060352</td>\n      <td>-0.011345</td>\n      <td>-0.059987</td>\n      <td>0.039882</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>791</th>\n      <td>software+engineer</td>\n      <td>-0.131392</td>\n      <td>-0.029033</td>\n      <td>-0.082744</td>\n      <td>-0.039305</td>\n      <td>-0.028481</td>\n      <td>-0.063193</td>\n      <td>-0.057688</td>\n      <td>0.128488</td>\n      <td>-0.072210</td>\n      <td>...</td>\n      <td>-0.023796</td>\n      <td>0.086397</td>\n      <td>-0.071659</td>\n      <td>-0.031082</td>\n      <td>-0.003570</td>\n      <td>0.047519</td>\n      <td>0.033251</td>\n      <td>-0.166673</td>\n      <td>-0.007538</td>\n      <td>-0.031994</td>\n    </tr>\n    <tr>\n      <th>792</th>\n      <td>software+engineer</td>\n      <td>-0.043274</td>\n      <td>-0.032123</td>\n      <td>0.041134</td>\n      <td>-0.017565</td>\n      <td>0.032743</td>\n      <td>-0.072493</td>\n      <td>0.013035</td>\n      <td>-0.040865</td>\n      <td>0.005068</td>\n      <td>...</td>\n      <td>0.003571</td>\n      <td>0.061880</td>\n      <td>0.018539</td>\n      <td>-0.087545</td>\n      <td>0.026615</td>\n      <td>0.099625</td>\n      <td>0.018813</td>\n      <td>-0.029922</td>\n      <td>0.014897</td>\n      <td>-0.003446</td>\n    </tr>\n    <tr>\n      <th>793</th>\n      <td>software+engineer</td>\n      <td>-0.006800</td>\n      <td>-0.087576</td>\n      <td>-0.029101</td>\n      <td>-0.043830</td>\n      <td>-0.068833</td>\n      <td>-0.016611</td>\n      <td>0.032965</td>\n      <td>0.086794</td>\n      <td>-0.112048</td>\n      <td>...</td>\n      <td>0.093700</td>\n      <td>0.060009</td>\n      <td>-0.031102</td>\n      <td>0.073509</td>\n      <td>0.054705</td>\n      <td>0.061826</td>\n      <td>0.028178</td>\n      <td>-0.001595</td>\n      <td>-0.046012</td>\n      <td>-0.033700</td>\n    </tr>\n    <tr>\n      <th>794</th>\n      <td>hr</td>\n      <td>-0.128770</td>\n      <td>0.043694</td>\n      <td>-0.002058</td>\n      <td>0.047944</td>\n      <td>-0.053523</td>\n      <td>0.042907</td>\n      <td>0.058572</td>\n      <td>-0.007716</td>\n      <td>-0.058442</td>\n      <td>...</td>\n      <td>-0.018871</td>\n      <td>0.036778</td>\n      <td>-0.042918</td>\n      <td>-0.002689</td>\n      <td>-0.052095</td>\n      <td>0.123027</td>\n      <td>0.064848</td>\n      <td>-0.024640</td>\n      <td>0.003905</td>\n      <td>0.014744</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>hr</td>\n      <td>-0.079189</td>\n      <td>0.014116</td>\n      <td>-0.021597</td>\n      <td>0.034801</td>\n      <td>-0.050730</td>\n      <td>-0.014727</td>\n      <td>-0.056692</td>\n      <td>-0.020434</td>\n      <td>-0.031112</td>\n      <td>...</td>\n      <td>0.056226</td>\n      <td>0.025051</td>\n      <td>0.044193</td>\n      <td>-0.059260</td>\n      <td>-0.099940</td>\n      <td>0.062814</td>\n      <td>0.032975</td>\n      <td>-0.039858</td>\n      <td>0.017513</td>\n      <td>-0.004559</td>\n    </tr>\n  </tbody>\n</table>\n<p>796 rows × 385 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "jd_train_X = jd_train.iloc[:, 1:]\n",
    "jd_train_y = jd_train[[\"category\"]]\n",
    "\n",
    "jd_test_X = jd_test.iloc[:, 1:]\n",
    "jd_test_y = jd_test[[\"category\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "category         \nsoftware+engineer    220\narts                 198\nsales                197\nhr                   181\ndtype: int64"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jd_test_y.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit(jd_train_y);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "[array(['arts', 'hr', 'sales', 'software+engineer'], dtype=object)]"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "jd_train_y = enc.transform(jd_train_y)\n",
    "jd_test_y = enc.transform(jd_test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64), input_shape=(384, 1)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 16:06:59.865227: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-31 16:07:00.094746: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-31 16:07:00.094869: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-31 16:07:01.112567: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-31 16:07:01.128403: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - ETA: 0s - loss: 1.3853 - accuracy: 0.2986 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 16:07:21.702871: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-31 16:07:21.806411: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-03-31 16:07:21.806441: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 27s 234ms/step - loss: 1.3853 - accuracy: 0.2986 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - val_loss: 1.3848 - val_accuracy: 0.2915 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 18s 180ms/step - loss: 1.3840 - accuracy: 0.3341 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - val_loss: 1.3833 - val_accuracy: 0.3681 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 18s 184ms/step - loss: 1.3799 - accuracy: 0.3438 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - val_loss: 1.3752 - val_accuracy: 0.3204 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 19s 186ms/step - loss: 1.3722 - accuracy: 0.3353 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - val_loss: 1.3700 - val_accuracy: 0.3153 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 19s 189ms/step - loss: 1.3613 - accuracy: 0.3510 - recall_2: 0.0000e+00 - precision_2: 0.0000e+00 - val_loss: 1.3588 - val_accuracy: 0.3693 - val_recall_2: 0.0000e+00 - val_precision_2: 0.0000e+00\n",
      "Epoch 6/50\n",
      " 43/100 [===========>..................] - ETA: 8s - loss: 1.3512 - accuracy: 0.3772 - recall_2: 7.2674e-04 - precision_2: 0.2000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [46]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mjd_train_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjd_train_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m50\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m30\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mjd_test_X\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjd_test_y\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint: disable=broad-except\u001B[39;00m\n\u001B[1;32m     66\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/keras/engine/training.py:1409\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1402\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1403\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   1404\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[1;32m   1405\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[1;32m   1406\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size,\n\u001B[1;32m   1407\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m   1408\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1409\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1410\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1411\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2450\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2451\u001B[0m   (graph_function,\n\u001B[1;32m   2452\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2453\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2454\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1856\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1857\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1858\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1859\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1860\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1861\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1862\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1863\u001B[0m     args,\n\u001B[1;32m   1864\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1865\u001B[0m     executing_eagerly)\n\u001B[1;32m   1866\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    495\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    496\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 497\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    503\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    504\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    505\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    506\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    509\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    510\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/miniforge3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(jd_train_X, jd_train_y, epochs=50, validation_steps=30, validation_data=(jd_test_X, jd_test_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"tf_models/rnn_easy.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hard Dataset (Distinct Job Categories)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "is_working_with_easy_dataset = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if is_working_with_easy_dataset:\n",
    "    input_train_filename = \"embedding_easy_train.csv\"\n",
    "    input_test_filename = \"embedding_easy_test.csv\"\n",
    "else:\n",
    "    input_train_filename = \"embedding_difficult_train.csv\"\n",
    "    input_test_filename = \"embedding_difficult_test.csv\"\n",
    "\n",
    "jd_train = pd.read_csv(input_train_filename, keep_default_na=False)\n",
    "jd_test = pd.read_csv(input_test_filename, keep_default_na=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jd_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jd_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Splitting Dataset into Features and Target Vectors"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jd_train_X = jd_train.iloc[:, 1:]\n",
    "jd_train_y = jd_train[[\"category\"]]\n",
    "\n",
    "jd_test_X = jd_test.iloc[:, 1:]\n",
    "jd_test_y = jd_test[[\"category\"]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jd_test_y.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Encoding Target Variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse=False)\n",
    "enc.fit(jd_train_y);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "jd_train_y = enc.transform(jd_train_y)\n",
    "jd_test_y = enc.transform(jd_test_y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### RNN Model creation and training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64), input_shape=(384, 1)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(4, activation='softmax')\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy', tf.keras.metrics.Recall(), tf.keras.metrics.Precision()])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = model.fit(jd_train_X, jd_train_y, epochs=50, validation_steps=30, validation_data=(jd_test_X, jd_test_y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plot_graphs(history, 'accuracy')\n",
    "plt.ylim(None, 1)\n",
    "plt.subplot(1, 2, 2)\n",
    "plot_graphs(history, 'loss')\n",
    "plt.ylim(0, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"tf_models/rnn_hard.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}